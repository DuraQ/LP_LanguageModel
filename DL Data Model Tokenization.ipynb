{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('https://alexip-ml.s3.amazonaws.com/stackexchange_812k.csv.gz', compression='gzip',\n",
    "                   error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">post_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">parent_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">comment_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comment</th>\n",
       "      <td>204612.774470</td>\n",
       "      <td>553076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>404266.732549</td>\n",
       "      <td>553076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>207538.857929</td>\n",
       "      <td>167304</td>\n",
       "      <td>185291.328589</td>\n",
       "      <td>75535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>219065.798642</td>\n",
       "      <td>91752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                post_id              parent_id            comment_id        \n",
       "                   mean   count           mean  count           mean   count\n",
       "category                                                                    \n",
       "comment   204612.774470  553076            NaN      0  404266.732549  553076\n",
       "post      207538.857929  167304  185291.328589  75535            NaN       0\n",
       "title     219065.798642   91752            NaN      0            NaN       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.groupby(['category']).agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_codeblock(text):\n",
    "    #regexp = re.compile(\"<pre>.*</pre>\")\n",
    "    regexp = re.compile(r'<pre>[-\\n\\w\\s\\d.]*</pre>')\n",
    "    return regexp.sub(\"\", text)\n",
    "\n",
    "def remove_table(text):\n",
    "    regexp = re.compile(\"<table>[-\\n\\w\\s\\d.]*</table>\")\n",
    "    return regexp.sub(\"\", text)\n",
    "\n",
    "def remove_html(text):\n",
    "    regexp = re.compile(\"<[a-z0-9/]*?>\")\n",
    "    return regexp.sub(\"\", text)\n",
    "\n",
    "def remove_latex(text):\n",
    "    regexp = re.compile(r'\\$.*?\\$')\n",
    "    return regexp.sub(\"\", text)\n",
    "\n",
    "def remove_handle(text):\n",
    "    regexp = re.compile(r'^@[a-zA-Z0-9\\.]*\\b\\s')\n",
    "    return regexp.sub(\"\", text)\n",
    "\n",
    "def remove_hyperlink(text):\n",
    "    regexp = re.compile(r'^\\[.*\\]\\(.*\\)')\n",
    "    return regexp.sub(\"\", text)\n",
    "\n",
    "def remove_whitespace(text):\n",
    "    regexp = re.compile(r'[\\r\\n\\t]*')\n",
    "    return regexp.sub(\"\", text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    regexp = re.compile(r'[^\\w\\s,\\.\\?]') #remove anthing that's not a word, space, comma, full stop or question mark.\n",
    "    return regexp.sub(\"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sub'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sub'] = data['sub'].apply(remove_codeblock)\n",
    "data['sub'] = data['sub'].apply(remove_table)\n",
    "data['sub'] = data['sub'].apply(remove_html)\n",
    "data['sub'] = data['sub'].apply(remove_latex)\n",
    "data['sub'] = data['sub'].apply(remove_handle)\n",
    "data['sub'] = data['sub'].apply(remove_hyperlink)\n",
    "data['sub'] = data['sub'].apply(remove_whitespace)\n",
    "data['sub'] = data['sub'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordPunctTokenizer\n",
    "data['token'] = data['sub'].apply(WordPunctTokenizer().tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"C:/Manning/DL/processedText.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>sub</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eliciting priors from experts</td>\n",
       "      <td>title</td>\n",
       "      <td>eliciting priors from experts</td>\n",
       "      <td>[eliciting, priors, from, experts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is normality?</td>\n",
       "      <td>title</td>\n",
       "      <td>what is normality?</td>\n",
       "      <td>[what, is, normality, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are some valuable Statistical Analysis op...</td>\n",
       "      <td>title</td>\n",
       "      <td>what are some valuable statistical analysis op...</td>\n",
       "      <td>[what, are, some, valuable, statistical, analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Assessing the significance of differences in d...</td>\n",
       "      <td>title</td>\n",
       "      <td>assessing the significance of differences in d...</td>\n",
       "      <td>[assessing, the, significance, of, differences...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Two Cultures: statistics vs. machine learn...</td>\n",
       "      <td>title</td>\n",
       "      <td>the two cultures statistics vs. machine learning?</td>\n",
       "      <td>[the, two, cultures, statistics, vs, ., machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Locating freely available data samples</td>\n",
       "      <td>title</td>\n",
       "      <td>locating freely available data samples</td>\n",
       "      <td>[locating, freely, available, data, samples]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So how many staticians *does* it take to screw...</td>\n",
       "      <td>title</td>\n",
       "      <td>so how many staticians does it take to screw i...</td>\n",
       "      <td>[so, how, many, staticians, does, it, take, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Under what conditions should Likert scales be ...</td>\n",
       "      <td>title</td>\n",
       "      <td>under what conditions should likert scales be ...</td>\n",
       "      <td>[under, what, conditions, should, likert, scal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Multivariate Interpolation Approaches</td>\n",
       "      <td>title</td>\n",
       "      <td>multivariate interpolation approaches</td>\n",
       "      <td>[multivariate, interpolation, approaches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forecasting demographic census</td>\n",
       "      <td>title</td>\n",
       "      <td>forecasting demographic census</td>\n",
       "      <td>[forecasting, demographic, census]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bayesian and frequentist reasoning in plain En...</td>\n",
       "      <td>title</td>\n",
       "      <td>bayesian and frequentist reasoning in plain en...</td>\n",
       "      <td>[bayesian, and, frequentist, reasoning, in, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Finding the PDF given the CDF</td>\n",
       "      <td>title</td>\n",
       "      <td>finding the pdf given the cdf</td>\n",
       "      <td>[finding, the, pdf, given, the, cdf]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools for modeling financial time series</td>\n",
       "      <td>title</td>\n",
       "      <td>tools for modeling financial time series</td>\n",
       "      <td>[tools, for, modeling, financial, time, series]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is a standard deviation?</td>\n",
       "      <td>title</td>\n",
       "      <td>what is a standard deviation?</td>\n",
       "      <td>[what, is, a, standard, deviation, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Testing random variate generation algorithms</td>\n",
       "      <td>title</td>\n",
       "      <td>testing random variate generation algorithms</td>\n",
       "      <td>[testing, random, variate, generation, algorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the meaning of p values and t values i...</td>\n",
       "      <td>title</td>\n",
       "      <td>what is the meaning of p values and t values i...</td>\n",
       "      <td>[what, is, the, meaning, of, p, values, and, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>R packages for seasonality analysis</td>\n",
       "      <td>title</td>\n",
       "      <td>r packages for seasonality analysis</td>\n",
       "      <td>[r, packages, for, seasonality, analysis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Examples for teaching: Correlation does not me...</td>\n",
       "      <td>title</td>\n",
       "      <td>examples for teaching correlation does not mea...</td>\n",
       "      <td>[examples, for, teaching, correlation, does, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pseudo-random number generation algorithms</td>\n",
       "      <td>title</td>\n",
       "      <td>pseudorandom number generation algorithms</td>\n",
       "      <td>[pseudorandom, number, generation, algorithms]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Explain data visualization</td>\n",
       "      <td>title</td>\n",
       "      <td>explain data visualization</td>\n",
       "      <td>[explain, data, visualization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clustering of large, heavy-tailed dataset</td>\n",
       "      <td>title</td>\n",
       "      <td>clustering of large, heavytailed dataset</td>\n",
       "      <td>[clustering, of, large, ,, heavytailed, dataset]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PCA on correlation or covariance?</td>\n",
       "      <td>title</td>\n",
       "      <td>pca on correlation or covariance?</td>\n",
       "      <td>[pca, on, correlation, or, covariance, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why do US and UK Schools Teach Different metho...</td>\n",
       "      <td>title</td>\n",
       "      <td>why do us and uk schools teach different metho...</td>\n",
       "      <td>[why, do, us, and, uk, schools, teach, differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Can someone please explain the back-propagatio...</td>\n",
       "      <td>title</td>\n",
       "      <td>can someone please explain the backpropagation...</td>\n",
       "      <td>[can, someone, please, explain, the, backpropa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>73</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What R packages do you find most useful in you...</td>\n",
       "      <td>title</td>\n",
       "      <td>what r packages do you find most useful in you...</td>\n",
       "      <td>[what, r, packages, do, you, find, most, usefu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Where can I find useful R tutorials with vario...</td>\n",
       "      <td>title</td>\n",
       "      <td>where can i find useful r tutorials with vario...</td>\n",
       "      <td>[where, can, i, find, useful, r, tutorials, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Robust nonparametric estimation of hazard/surv...</td>\n",
       "      <td>title</td>\n",
       "      <td>robust nonparametric estimation of hazardsurvi...</td>\n",
       "      <td>[robust, nonparametric, estimation, of, hazard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How Large a Difference Can Be Expected Between...</td>\n",
       "      <td>title</td>\n",
       "      <td>how large a difference can be expected between...</td>\n",
       "      <td>[how, large, a, difference, can, be, expected,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are good basic statistics to use for ordi...</td>\n",
       "      <td>title</td>\n",
       "      <td>what are good basic statistics to use for ordi...</td>\n",
       "      <td>[what, are, good, basic, statistics, to, use, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is your favorite data visualization blog?</td>\n",
       "      <td>title</td>\n",
       "      <td>what is your favorite data visualization blog?</td>\n",
       "      <td>[what, is, your, favorite, data, visualization...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812102</th>\n",
       "      <td>279971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536464.0</td>\n",
       "      <td>If you're running logistic regression, you cou...</td>\n",
       "      <td>comment</td>\n",
       "      <td>if youre running logistic regression, you coul...</td>\n",
       "      <td>[if, youre, running, logistic, regression, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812103</th>\n",
       "      <td>279971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536466.0</td>\n",
       "      <td>@MatthewGunn I will try what you said, BUT you...</td>\n",
       "      <td>comment</td>\n",
       "      <td>i will try what you said, but you were right a...</td>\n",
       "      <td>[i, will, try, what, you, said, ,, but, you, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812104</th>\n",
       "      <td>279971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536450.0</td>\n",
       "      <td>You are incorrectly evaluating your regression...</td>\n",
       "      <td>comment</td>\n",
       "      <td>you are incorrectly evaluating your regression...</td>\n",
       "      <td>[you, are, incorrectly, evaluating, your, regr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812105</th>\n",
       "      <td>279978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536404.0</td>\n",
       "      <td>Can you post an erxcerpt of the data?</td>\n",
       "      <td>comment</td>\n",
       "      <td>can you post an erxcerpt of the data?</td>\n",
       "      <td>[can, you, post, an, erxcerpt, of, the, data, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812106</th>\n",
       "      <td>279982</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536512.0</td>\n",
       "      <td>You appear to be plotting the *negative* of th...</td>\n",
       "      <td>comment</td>\n",
       "      <td>you appear to be plotting the negative of the ...</td>\n",
       "      <td>[you, appear, to, be, plotting, the, negative,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812107</th>\n",
       "      <td>279984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536726.0</td>\n",
       "      <td>Btw, yes it's true that the variance for a bin...</td>\n",
       "      <td>comment</td>\n",
       "      <td>btw, yes its true that the variance for a bino...</td>\n",
       "      <td>[btw, ,, yes, its, true, that, the, variance, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812108</th>\n",
       "      <td>279984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536729.0</td>\n",
       "      <td>@P.Windridge 1st comment: I'm assuming that my...</td>\n",
       "      <td>comment</td>\n",
       "      <td>1st comment im assuming that my found  are my ...</td>\n",
       "      <td>[1st, comment, im, assuming, that, my, found, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812109</th>\n",
       "      <td>279984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536722.0</td>\n",
       "      <td>Assuming your matrix simulations are independe...</td>\n",
       "      <td>comment</td>\n",
       "      <td>assuming your matrix simulations are independe...</td>\n",
       "      <td>[assuming, your, matrix, simulations, are, ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812110</th>\n",
       "      <td>279984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537256.0</td>\n",
       "      <td>To help your intuition: with $54$ successes ou...</td>\n",
       "      <td>comment</td>\n",
       "      <td>to help your intuition with  successes out of ...</td>\n",
       "      <td>[to, help, your, intuition, with, successes, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812111</th>\n",
       "      <td>279984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537280.0</td>\n",
       "      <td>@whuber Yes, that I think I understand. My que...</td>\n",
       "      <td>comment</td>\n",
       "      <td>yes, that i think i understand. my question is...</td>\n",
       "      <td>[yes, ,, that, i, think, i, understand, ., my,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812112</th>\n",
       "      <td>279984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537281.0</td>\n",
       "      <td>You could use either (or even something else)....</td>\n",
       "      <td>comment</td>\n",
       "      <td>you could use either or even something else.  ...</td>\n",
       "      <td>[you, could, use, either, or, even, something,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812113</th>\n",
       "      <td>279984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537298.0</td>\n",
       "      <td>You write \"which might be wise\" - could you ex...</td>\n",
       "      <td>comment</td>\n",
       "      <td>you write which might be wise  could you expan...</td>\n",
       "      <td>[you, write, which, might, be, wise, could, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812114</th>\n",
       "      <td>279984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538795.0</td>\n",
       "      <td>This does not answer your question. But I woul...</td>\n",
       "      <td>comment</td>\n",
       "      <td>this does not answer your question. but i woul...</td>\n",
       "      <td>[this, does, not, answer, your, question, ., b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812115</th>\n",
       "      <td>279985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>573936.0</td>\n",
       "      <td>[This answer](https://stats.stackexchange.com/...</td>\n",
       "      <td>comment</td>\n",
       "      <td>to a closely related question might be of int...</td>\n",
       "      <td>[to, a, closely, related, question, might, be,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812116</th>\n",
       "      <td>279989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536431.0</td>\n",
       "      <td>Your assumed data generating process doesn't m...</td>\n",
       "      <td>comment</td>\n",
       "      <td>your assumed data generating process doesnt ma...</td>\n",
       "      <td>[your, assumed, data, generating, process, doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812117</th>\n",
       "      <td>279989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536469.0</td>\n",
       "      <td>My apologies for not being more clear! The equ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>my apologies for not being more clear the equa...</td>\n",
       "      <td>[my, apologies, for, not, being, more, clear, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812118</th>\n",
       "      <td>279990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537434.0</td>\n",
       "      <td>I am working on supply response of selected ag...</td>\n",
       "      <td>comment</td>\n",
       "      <td>i am working on supply response of selected ag...</td>\n",
       "      <td>[i, am, working, on, supply, response, of, sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812119</th>\n",
       "      <td>279990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>537435.0</td>\n",
       "      <td>One thing to keep in mind is that inference af...</td>\n",
       "      <td>comment</td>\n",
       "      <td>one thing to keep in mind is that inference af...</td>\n",
       "      <td>[one, thing, to, keep, in, mind, is, that, inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812120</th>\n",
       "      <td>279990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536590.0</td>\n",
       "      <td>This question is more general than just the AR...</td>\n",
       "      <td>comment</td>\n",
       "      <td>this question is more general than just the ar...</td>\n",
       "      <td>[this, question, is, more, general, than, just...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812121</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536603.0</td>\n",
       "      <td>Btw your plot doesn't look like a ROC curve, w...</td>\n",
       "      <td>comment</td>\n",
       "      <td>btw your plot doesnt look like a roc curve, wh...</td>\n",
       "      <td>[btw, your, plot, doesnt, look, like, a, roc, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812122</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536604.0</td>\n",
       "      <td>@Calimo i just plotted the results of each con...</td>\n",
       "      <td>comment</td>\n",
       "      <td>i just plotted the results of each confusion m...</td>\n",
       "      <td>[i, just, plotted, the, results, of, each, con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812123</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536608.0</td>\n",
       "      <td>Ok, but then that's not a ROC curve, which sho...</td>\n",
       "      <td>comment</td>\n",
       "      <td>ok, but then thats not a roc curve, which show...</td>\n",
       "      <td>[ok, ,, but, then, thats, not, a, roc, curve, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812124</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536612.0</td>\n",
       "      <td>@Calimo yes i understand. but therein lies my ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>yes i understand. but therein lies my question...</td>\n",
       "      <td>[yes, i, understand, ., but, therein, lies, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812125</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536451.0</td>\n",
       "      <td>You really want a cost function...</td>\n",
       "      <td>comment</td>\n",
       "      <td>you really want a cost function...</td>\n",
       "      <td>[you, really, want, a, cost, function, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812126</th>\n",
       "      <td>279993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536454.0</td>\n",
       "      <td>@Calimo it would seem so, stumbled upon `What ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>it would seem so, stumbled upon what roc curve...</td>\n",
       "      <td>[it, would, seem, so, ,, stumbled, upon, what,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812127</th>\n",
       "      <td>279994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536471.0</td>\n",
       "      <td>It does run, and gives very valid looking esti...</td>\n",
       "      <td>comment</td>\n",
       "      <td>it does run, and gives very valid looking esti...</td>\n",
       "      <td>[it, does, run, ,, and, gives, very, valid, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812128</th>\n",
       "      <td>279998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536439.0</td>\n",
       "      <td>It seems to me that you are correct; the doubl...</td>\n",
       "      <td>comment</td>\n",
       "      <td>it seems to me that you are correct the double...</td>\n",
       "      <td>[it, seems, to, me, that, you, are, correct, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812129</th>\n",
       "      <td>279998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536514.0</td>\n",
       "      <td>It wouldn't be the first time a grader has mis...</td>\n",
       "      <td>comment</td>\n",
       "      <td>it wouldnt be the first time a grader has miss...</td>\n",
       "      <td>[it, wouldnt, be, the, first, time, a, grader,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812130</th>\n",
       "      <td>279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>536802.0</td>\n",
       "      <td>The basic idea is to compare the clustering co...</td>\n",
       "      <td>comment</td>\n",
       "      <td>the basic idea is to compare the clustering co...</td>\n",
       "      <td>[the, basic, idea, is, to, compare, the, clust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812131</th>\n",
       "      <td>279999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>542550.0</td>\n",
       "      <td>As per your other question, your data does not...</td>\n",
       "      <td>comment</td>\n",
       "      <td>as per your other question, your data does not...</td>\n",
       "      <td>[as, per, your, other, question, ,, your, data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>812132 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        post_id  parent_id  comment_id  \\\n",
       "0             1        NaN         NaN   \n",
       "1             2        NaN         NaN   \n",
       "2             3        NaN         NaN   \n",
       "3             4        NaN         NaN   \n",
       "4             6        NaN         NaN   \n",
       "5             7        NaN         NaN   \n",
       "6             8        NaN         NaN   \n",
       "7            10        NaN         NaN   \n",
       "8            11        NaN         NaN   \n",
       "9            21        NaN         NaN   \n",
       "10           22        NaN         NaN   \n",
       "11           23        NaN         NaN   \n",
       "12           25        NaN         NaN   \n",
       "13           26        NaN         NaN   \n",
       "14           30        NaN         NaN   \n",
       "15           31        NaN         NaN   \n",
       "16           33        NaN         NaN   \n",
       "17           36        NaN         NaN   \n",
       "18           40        NaN         NaN   \n",
       "19           44        NaN         NaN   \n",
       "20           47        NaN         NaN   \n",
       "21           53        NaN         NaN   \n",
       "22           54        NaN         NaN   \n",
       "23           58        NaN         NaN   \n",
       "24           73        NaN         NaN   \n",
       "25           75        NaN         NaN   \n",
       "26           93        NaN         NaN   \n",
       "27           95        NaN         NaN   \n",
       "28           97        NaN         NaN   \n",
       "29          103        NaN         NaN   \n",
       "...         ...        ...         ...   \n",
       "812102   279971        NaN    536464.0   \n",
       "812103   279971        NaN    536466.0   \n",
       "812104   279971        NaN    536450.0   \n",
       "812105   279978        NaN    536404.0   \n",
       "812106   279982        NaN    536512.0   \n",
       "812107   279984        NaN    536726.0   \n",
       "812108   279984        NaN    536729.0   \n",
       "812109   279984        NaN    536722.0   \n",
       "812110   279984        NaN    537256.0   \n",
       "812111   279984        NaN    537280.0   \n",
       "812112   279984        NaN    537281.0   \n",
       "812113   279984        NaN    537298.0   \n",
       "812114   279984        NaN    538795.0   \n",
       "812115   279985        NaN    573936.0   \n",
       "812116   279989        NaN    536431.0   \n",
       "812117   279989        NaN    536469.0   \n",
       "812118   279990        NaN    537434.0   \n",
       "812119   279990        NaN    537435.0   \n",
       "812120   279990        NaN    536590.0   \n",
       "812121   279993        NaN    536603.0   \n",
       "812122   279993        NaN    536604.0   \n",
       "812123   279993        NaN    536608.0   \n",
       "812124   279993        NaN    536612.0   \n",
       "812125   279993        NaN    536451.0   \n",
       "812126   279993        NaN    536454.0   \n",
       "812127   279994        NaN    536471.0   \n",
       "812128   279998        NaN    536439.0   \n",
       "812129   279998        NaN    536514.0   \n",
       "812130   279999        NaN    536802.0   \n",
       "812131   279999        NaN    542550.0   \n",
       "\n",
       "                                                     text category  \\\n",
       "0                           Eliciting priors from experts    title   \n",
       "1                                      What is normality?    title   \n",
       "2       What are some valuable Statistical Analysis op...    title   \n",
       "3       Assessing the significance of differences in d...    title   \n",
       "4       The Two Cultures: statistics vs. machine learn...    title   \n",
       "5                  Locating freely available data samples    title   \n",
       "6       So how many staticians *does* it take to screw...    title   \n",
       "7       Under what conditions should Likert scales be ...    title   \n",
       "8                   Multivariate Interpolation Approaches    title   \n",
       "9                          Forecasting demographic census    title   \n",
       "10      Bayesian and frequentist reasoning in plain En...    title   \n",
       "11                          Finding the PDF given the CDF    title   \n",
       "12               Tools for modeling financial time series    title   \n",
       "13                          What is a standard deviation?    title   \n",
       "14           Testing random variate generation algorithms    title   \n",
       "15      What is the meaning of p values and t values i...    title   \n",
       "16                    R packages for seasonality analysis    title   \n",
       "17      Examples for teaching: Correlation does not me...    title   \n",
       "18             Pseudo-random number generation algorithms    title   \n",
       "19                             Explain data visualization    title   \n",
       "20              Clustering of large, heavy-tailed dataset    title   \n",
       "21                      PCA on correlation or covariance?    title   \n",
       "22      Why do US and UK Schools Teach Different metho...    title   \n",
       "23      Can someone please explain the back-propagatio...    title   \n",
       "24      What R packages do you find most useful in you...    title   \n",
       "25      Where can I find useful R tutorials with vario...    title   \n",
       "26      Robust nonparametric estimation of hazard/surv...    title   \n",
       "27      How Large a Difference Can Be Expected Between...    title   \n",
       "28      What are good basic statistics to use for ordi...    title   \n",
       "29         What is your favorite data visualization blog?    title   \n",
       "...                                                   ...      ...   \n",
       "812102  If you're running logistic regression, you cou...  comment   \n",
       "812103  @MatthewGunn I will try what you said, BUT you...  comment   \n",
       "812104  You are incorrectly evaluating your regression...  comment   \n",
       "812105              Can you post an erxcerpt of the data?  comment   \n",
       "812106  You appear to be plotting the *negative* of th...  comment   \n",
       "812107  Btw, yes it's true that the variance for a bin...  comment   \n",
       "812108  @P.Windridge 1st comment: I'm assuming that my...  comment   \n",
       "812109  Assuming your matrix simulations are independe...  comment   \n",
       "812110  To help your intuition: with $54$ successes ou...  comment   \n",
       "812111  @whuber Yes, that I think I understand. My que...  comment   \n",
       "812112  You could use either (or even something else)....  comment   \n",
       "812113  You write \"which might be wise\" - could you ex...  comment   \n",
       "812114  This does not answer your question. But I woul...  comment   \n",
       "812115  [This answer](https://stats.stackexchange.com/...  comment   \n",
       "812116  Your assumed data generating process doesn't m...  comment   \n",
       "812117  My apologies for not being more clear! The equ...  comment   \n",
       "812118  I am working on supply response of selected ag...  comment   \n",
       "812119  One thing to keep in mind is that inference af...  comment   \n",
       "812120  This question is more general than just the AR...  comment   \n",
       "812121  Btw your plot doesn't look like a ROC curve, w...  comment   \n",
       "812122  @Calimo i just plotted the results of each con...  comment   \n",
       "812123  Ok, but then that's not a ROC curve, which sho...  comment   \n",
       "812124  @Calimo yes i understand. but therein lies my ...  comment   \n",
       "812125                 You really want a cost function...  comment   \n",
       "812126  @Calimo it would seem so, stumbled upon `What ...  comment   \n",
       "812127  It does run, and gives very valid looking esti...  comment   \n",
       "812128  It seems to me that you are correct; the doubl...  comment   \n",
       "812129  It wouldn't be the first time a grader has mis...  comment   \n",
       "812130  The basic idea is to compare the clustering co...  comment   \n",
       "812131  As per your other question, your data does not...  comment   \n",
       "\n",
       "                                                      sub  \\\n",
       "0                           eliciting priors from experts   \n",
       "1                                      what is normality?   \n",
       "2       what are some valuable statistical analysis op...   \n",
       "3       assessing the significance of differences in d...   \n",
       "4       the two cultures statistics vs. machine learning?   \n",
       "5                  locating freely available data samples   \n",
       "6       so how many staticians does it take to screw i...   \n",
       "7       under what conditions should likert scales be ...   \n",
       "8                   multivariate interpolation approaches   \n",
       "9                          forecasting demographic census   \n",
       "10      bayesian and frequentist reasoning in plain en...   \n",
       "11                          finding the pdf given the cdf   \n",
       "12               tools for modeling financial time series   \n",
       "13                          what is a standard deviation?   \n",
       "14           testing random variate generation algorithms   \n",
       "15      what is the meaning of p values and t values i...   \n",
       "16                    r packages for seasonality analysis   \n",
       "17      examples for teaching correlation does not mea...   \n",
       "18              pseudorandom number generation algorithms   \n",
       "19                             explain data visualization   \n",
       "20               clustering of large, heavytailed dataset   \n",
       "21                      pca on correlation or covariance?   \n",
       "22      why do us and uk schools teach different metho...   \n",
       "23      can someone please explain the backpropagation...   \n",
       "24      what r packages do you find most useful in you...   \n",
       "25      where can i find useful r tutorials with vario...   \n",
       "26      robust nonparametric estimation of hazardsurvi...   \n",
       "27      how large a difference can be expected between...   \n",
       "28      what are good basic statistics to use for ordi...   \n",
       "29         what is your favorite data visualization blog?   \n",
       "...                                                   ...   \n",
       "812102  if youre running logistic regression, you coul...   \n",
       "812103  i will try what you said, but you were right a...   \n",
       "812104  you are incorrectly evaluating your regression...   \n",
       "812105              can you post an erxcerpt of the data?   \n",
       "812106  you appear to be plotting the negative of the ...   \n",
       "812107  btw, yes its true that the variance for a bino...   \n",
       "812108  1st comment im assuming that my found  are my ...   \n",
       "812109  assuming your matrix simulations are independe...   \n",
       "812110  to help your intuition with  successes out of ...   \n",
       "812111  yes, that i think i understand. my question is...   \n",
       "812112  you could use either or even something else.  ...   \n",
       "812113  you write which might be wise  could you expan...   \n",
       "812114  this does not answer your question. but i woul...   \n",
       "812115   to a closely related question might be of int...   \n",
       "812116  your assumed data generating process doesnt ma...   \n",
       "812117  my apologies for not being more clear the equa...   \n",
       "812118  i am working on supply response of selected ag...   \n",
       "812119  one thing to keep in mind is that inference af...   \n",
       "812120  this question is more general than just the ar...   \n",
       "812121  btw your plot doesnt look like a roc curve, wh...   \n",
       "812122  i just plotted the results of each confusion m...   \n",
       "812123  ok, but then thats not a roc curve, which show...   \n",
       "812124  yes i understand. but therein lies my question...   \n",
       "812125                 you really want a cost function...   \n",
       "812126  it would seem so, stumbled upon what roc curve...   \n",
       "812127  it does run, and gives very valid looking esti...   \n",
       "812128  it seems to me that you are correct the double...   \n",
       "812129  it wouldnt be the first time a grader has miss...   \n",
       "812130  the basic idea is to compare the clustering co...   \n",
       "812131  as per your other question, your data does not...   \n",
       "\n",
       "                                                    token  \n",
       "0                      [eliciting, priors, from, experts]  \n",
       "1                                [what, is, normality, ?]  \n",
       "2       [what, are, some, valuable, statistical, analy...  \n",
       "3       [assessing, the, significance, of, differences...  \n",
       "4       [the, two, cultures, statistics, vs, ., machin...  \n",
       "5            [locating, freely, available, data, samples]  \n",
       "6       [so, how, many, staticians, does, it, take, to...  \n",
       "7       [under, what, conditions, should, likert, scal...  \n",
       "8               [multivariate, interpolation, approaches]  \n",
       "9                      [forecasting, demographic, census]  \n",
       "10      [bayesian, and, frequentist, reasoning, in, pl...  \n",
       "11                   [finding, the, pdf, given, the, cdf]  \n",
       "12        [tools, for, modeling, financial, time, series]  \n",
       "13                  [what, is, a, standard, deviation, ?]  \n",
       "14      [testing, random, variate, generation, algorit...  \n",
       "15      [what, is, the, meaning, of, p, values, and, t...  \n",
       "16              [r, packages, for, seasonality, analysis]  \n",
       "17      [examples, for, teaching, correlation, does, n...  \n",
       "18         [pseudorandom, number, generation, algorithms]  \n",
       "19                         [explain, data, visualization]  \n",
       "20       [clustering, of, large, ,, heavytailed, dataset]  \n",
       "21              [pca, on, correlation, or, covariance, ?]  \n",
       "22      [why, do, us, and, uk, schools, teach, differe...  \n",
       "23      [can, someone, please, explain, the, backpropa...  \n",
       "24      [what, r, packages, do, you, find, most, usefu...  \n",
       "25      [where, can, i, find, useful, r, tutorials, wi...  \n",
       "26      [robust, nonparametric, estimation, of, hazard...  \n",
       "27      [how, large, a, difference, can, be, expected,...  \n",
       "28      [what, are, good, basic, statistics, to, use, ...  \n",
       "29      [what, is, your, favorite, data, visualization...  \n",
       "...                                                   ...  \n",
       "812102  [if, youre, running, logistic, regression, ,, ...  \n",
       "812103  [i, will, try, what, you, said, ,, but, you, w...  \n",
       "812104  [you, are, incorrectly, evaluating, your, regr...  \n",
       "812105   [can, you, post, an, erxcerpt, of, the, data, ?]  \n",
       "812106  [you, appear, to, be, plotting, the, negative,...  \n",
       "812107  [btw, ,, yes, its, true, that, the, variance, ...  \n",
       "812108  [1st, comment, im, assuming, that, my, found, ...  \n",
       "812109  [assuming, your, matrix, simulations, are, ind...  \n",
       "812110  [to, help, your, intuition, with, successes, o...  \n",
       "812111  [yes, ,, that, i, think, i, understand, ., my,...  \n",
       "812112  [you, could, use, either, or, even, something,...  \n",
       "812113  [you, write, which, might, be, wise, could, yo...  \n",
       "812114  [this, does, not, answer, your, question, ., b...  \n",
       "812115  [to, a, closely, related, question, might, be,...  \n",
       "812116  [your, assumed, data, generating, process, doe...  \n",
       "812117  [my, apologies, for, not, being, more, clear, ...  \n",
       "812118  [i, am, working, on, supply, response, of, sel...  \n",
       "812119  [one, thing, to, keep, in, mind, is, that, inf...  \n",
       "812120  [this, question, is, more, general, than, just...  \n",
       "812121  [btw, your, plot, doesnt, look, like, a, roc, ...  \n",
       "812122  [i, just, plotted, the, results, of, each, con...  \n",
       "812123  [ok, ,, but, then, thats, not, a, roc, curve, ...  \n",
       "812124  [yes, i, understand, ., but, therein, lies, my...  \n",
       "812125        [you, really, want, a, cost, function, ...]  \n",
       "812126  [it, would, seem, so, ,, stumbled, upon, what,...  \n",
       "812127  [it, does, run, ,, and, gives, very, valid, lo...  \n",
       "812128  [it, seems, to, me, that, you, are, correct, t...  \n",
       "812129  [it, wouldnt, be, the, first, time, a, grader,...  \n",
       "812130  [the, basic, idea, is, to, compare, the, clust...  \n",
       "812131  [as, per, your, other, question, ,, your, data...  \n",
       "\n",
       "[812132 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
